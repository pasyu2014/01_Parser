# 01_Parser

# Веб-парсер для сбора ссылок

Этот проект представляет собой веб-парсер, который может извлекать ссылки с веб-страниц. Парсер может быть полезным инструментом для сбора ссылок с веб-страниц. 

## Описание

Парсер отправляет GET-запрос на указанный URL, парсит страницу с помощью BeautifulSoup и собирает уникальные внешние ссылки. Он также поддерживает возможность сохранения результатов в файл и ограничения по глубине парсинга.

### Примеры полезных запросов

Вот 10 примеров полезных запросов, которые можно реализовать на основе программы, и для чего они могут пригодиться:

1. **Сбор всех внешних ссылок на странице**  
   **Цель:** Получить все ссылки, которые ведут на другие сайты, для анализа внешних ресурсов.  
   **Реализация:** Использовать функцию `get_links(url)` для получения всех уникальных внешних ссылок.

2. **Анализ ссылок конкурентов**  
   **Цель:** Изучить, на какие внешние ресурсы ссылаются конкуренты, для выявления стратегий линкбилдинга.  
   **Реализация:** Запустить парсер на URL-адресах конкурентов и собрать их внешние ссылки.

3. **Сбор ссылок для создания обратных ссылок**  
   **Цель:** Найти сайты, которые могут быть заинтересованы в обратной ссылке на ваш контент.  
   **Реализация:** Использовать парсер для нахождения релевантных ресурсов.

4. **Сохранение ссылок для дальнейшего анализа**  
   **Цель:** Сохранить все собранные ссылки для последующего анализа в Excel или других инструментах.  
   **Реализация:** Указать имя файла при запуске парсера для записи результатов.

5. **Сравнение ссылок между страницами**  
   **Цель:** Определить, какие ссылки присутствуют на одной странице, но отсутствуют на другой.  
   **Реализация:** Запустить парсер на двух разных URL и сравнить результаты.

6. **Аудит ссылок на сайте**  
   **Цель:** Проверить, какие ссылки на сайте ведут на несуществующие страницы или 404 ошибки.  
   **Реализация:** Использовать парсер для сбора всех ссылок на сайте и провести их проверку.

7. **Сбор ссылок для поиска партнеров**  
   **Цель:** Найти сайты, с которыми можно сотрудничать или обмениваться ссылками.  
   **Реализация:** Извлечь ссылки с тематических страниц и проанализировать их.

8. **Мониторинг изменений на странице**  
   **Цель:** Отслеживать изменения в ссылках на страницах, чтобы быстро реагировать на изменения.  
   **Реализация:** Периодически запускать парсер и сравнивать результаты.

9. **Сбор ссылок для SEO-анализа**  
   **Цель:** Собрать ссылки для дальнейшего анализа SEO и линкбилдинга.  
   **Реализация:** Использовать парсер для получения данных о внешних ссылках целевых страниц.

10. **Изучение структуры сайтов**  
    **Цель:** Понять, как организованы ссылки на сайте, чтобы улучшить собственный веб-дизайн.  
    **Реализация:** Запустить парсер на сайте и проанализировать структуру ссылок.

## Установка

1. Склонируйте репозиторий:
   ```bash
   git clone https://github.com/pasyu2014/01_Parser
   cd 01_Parser
   ```

2. Установите необходимые библиотеки:
   ```bash
   pip install requests beautifulsoup4
   ```

## Запуск

Чтобы запустить парсер, выполните следующий команду:
```bash
python parser.py
```

Следуйте инструкциям на экране, чтобы ввести URL для парсинга, глубину и выбрать, хотите ли вы выводить результаты в терминал или сохранять их в файл.

## Использование

После запуска программы:

1. Введите URL-адрес, который вы хотите парсить.
2. Укажите глубину парсинга (0 — только начальный URL).
3. Выберите, выводить ли результаты в терминал или сохранять в файл. 

## Особенности данных

При вызове parse_links используются следующие параметры

   start_url: URL-адрес, с которого начинается парсинг
   depth: Глубина парсинга
   output_file: Имя файла для сохранения результата (если требуется)

Функция parse_links возвращает множество посещённых ссылок. Именно посещенных. При depth = 0 или = 1  она возвращает URL-адрес, с которого начинается парсинг.

В то время как в файл записываются все URL-адреса имевшиеся и имеющиеся на посещаемых при текущей глубине вложенности url-страницах.
   

## Лицензия

Этот проект лицензирован под MIT License - подробности смотрите в файле LICENSE.
```

Этот файл README.md содержит информацию о проекте, его установке, запуске и использовании, а также примеры полезных запросов, которые можно реализовать с помощью парсера.
